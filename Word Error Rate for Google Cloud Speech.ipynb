{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import Audio, display\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "# Sets authentication environment variable\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'auth/Chemistry-NU.json'\n",
    "\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "def gcs(signal, fs):\n",
    "    audio = types.RecognitionAudio(content=signal.tobytes())\n",
    "\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=fs,\n",
    "        language_code='en-US',\n",
    "        max_alternatives=1,\n",
    "        model='video')\n",
    "        #enable_automatic_punctuation=True,\n",
    "        #audio_channel_count=6,\n",
    "        #enable_separate_recognition_per_channel=True)\n",
    "        \n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config, audio)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Error Rate calculation based on jiwer: https://github.com/jitsi/asr-wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer(human_transcript, asr_transcript):\n",
    "    vocab = []\n",
    "\n",
    "    for word in human_transcript + asr_transcript:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "    \n",
    "    # Represent transcripts as numbers\n",
    "    h = []\n",
    "    a = []\n",
    "\n",
    "    for word in human_transcript:\n",
    "        h.append(vocab.index(word))\n",
    "\n",
    "    for word in asr_transcript:\n",
    "        a.append(vocab.index(word))\n",
    "\n",
    "    # Alignment\n",
    "    distance = _edit_distance(h, a)\n",
    "\n",
    "    # Calculate WER from edit distance\n",
    "    n = len(human_transcript)\n",
    "    word_error_rate = distance / n\n",
    "\n",
    "    return word_error_rate\n",
    "\n",
    "def _edit_distance(a, b):\n",
    "    # Calculate edit distance based on Wagner-Fischer algorithm\n",
    "    if len(a) == 0:\n",
    "        raise ValueError('Reference string cannot be empty.')\n",
    "    elif len(b) == 0:\n",
    "        return len(a)\n",
    "\n",
    "    # Initialize matrix and set the first row and column equal to 1, 2, 3, ...\n",
    "    # Each column represents a single token in the reference string a\n",
    "    # Each row represents a single token in the reference string b\n",
    "    \n",
    "    m = np.zeros((len(b) + 1, len(a) + 1), dtype=np.int32)\n",
    "\n",
    "    m[0, 1:] = np.arange(1, len(a) + 1)\n",
    "    m[1:, 0] = np.arange(1, len(b) + 1)\n",
    "\n",
    "    # Loop over remaining cells (from second row and column onwards)\n",
    "    # The value of each selected cell is:\n",
    "    #   if token represented by row == token represented by column:\n",
    "    #       value of the top-left diagonal cell\n",
    "    #   else:\n",
    "    #       calculate 3 values:\n",
    "    #            * top-left diagonal cell + 1 (which represents substitution)\n",
    "    #            * left cell + 1 (representing deleting)\n",
    "    #            * top cell + 1 (representing insertion)\n",
    "    #       value of the smallest of the three\n",
    "    \n",
    "    for i in range(1, m.shape[0]):\n",
    "        for j in range(1, m.shape[1]):\n",
    "            if a[j-1] == b[i-1]:\n",
    "                m[i, j] = m[i-1, j-1]\n",
    "            else:\n",
    "                m[i, j] = min(\n",
    "                    m[i-1, j-1] + 1,\n",
    "                    m[i, j-1] + 1,\n",
    "                    m[i-1, j] + 1\n",
    "                )\n",
    "\n",
    "    # The minimum-edit distance is the value of the bottom-right cell of matrix\n",
    "    return m[len(b), len(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, recording = wavfile.read('audio/Sony In lab Audio/32.wav')\n",
    "recording = recording[:,0] # Grab 1st channel\n",
    "\n",
    "# recording = recording[:,:6] # Grab 6 channels\n",
    "# combined_channels = np.zeros(len(recording), dtype=np.int16)\n",
    "# for col in range(recording.shape[1]):\n",
    "#     combined_channels += recording[:,col]\n",
    "# combined_channels //= 6\n",
    "# recording = combined_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('audio/Sony In lab Audio/32.txt', 'r') as f:\n",
    "    timestamps = []\n",
    "    utterances = []\n",
    "    for line in f.readlines():\n",
    "        timestamp = line[1:9]\n",
    "        line = re.sub('\\[.*?\\]', ' ', line) # remove timestamps and inaudible\n",
    "        try:\n",
    "            line = line[line.index(':'):]\n",
    "        except ValueError:\n",
    "            continue\n",
    "        line = line.replace('...', ' ') # replace ellipses with spaces\n",
    "        line = line.translate(str.maketrans('', '', '!\"#&()*+,./:;<=>?@[\\\\]^_`{|}~')) # remove punctuation\n",
    "        line = re.sub(' +', ' ', line) # replace double spaces with single spaces\n",
    "        line = line.strip('\\n ') # remove newline character and leading/trailing spaces\n",
    "        timestamps.append(timestamp)\n",
    "        utterances.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds = []\n",
    "for time in timestamps:\n",
    "    seconds.append(int(time[3:5]) * 60 + int(time[6:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [s * fs for s in seconds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = []\n",
    "for t in range(0, len(frames) - 1):\n",
    "    if frames[t] == frames[t + 1]:\n",
    "        clips.append(recording[frames[t]:frames[t + 2] + 16000])\n",
    "    else:\n",
    "        clips.append(recording[frames[t]:frames[t + 1] + 16000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting response for clip 0\n",
      "Getting response for clip 1\n",
      "Getting response for clip 2\n",
      "Getting response for clip 3\n",
      "Getting response for clip 4\n",
      "Getting response for clip 5\n",
      "Getting response for clip 6\n",
      "Getting response for clip 7\n",
      "Getting response for clip 8\n",
      "Getting response for clip 9\n",
      "Getting response for clip 10\n",
      "Getting response for clip 11\n",
      "Getting response for clip 12\n",
      "Getting response for clip 13\n",
      "Getting response for clip 14\n",
      "Getting response for clip 15\n",
      "Getting response for clip 16\n",
      "Getting response for clip 17\n",
      "Getting response for clip 18\n",
      "Getting response for clip 19\n",
      "Getting response for clip 20\n",
      "Getting response for clip 21\n",
      "Getting response for clip 22\n",
      "Getting response for clip 23\n",
      "Getting response for clip 24\n",
      "Getting response for clip 25\n",
      "Getting response for clip 26\n",
      "Getting response for clip 27\n",
      "Getting response for clip 28\n",
      "Getting response for clip 29\n",
      "Getting response for clip 30\n",
      "Getting response for clip 31\n",
      "Getting response for clip 32\n",
      "Getting response for clip 33\n",
      "Getting response for clip 34\n",
      "Getting response for clip 35\n",
      "Getting response for clip 36\n",
      "Getting response for clip 37\n",
      "Getting response for clip 38\n",
      "Getting response for clip 39\n",
      "Getting response for clip 40\n",
      "Getting response for clip 41\n",
      "Getting response for clip 42\n",
      "Getting response for clip 43\n",
      "Getting response for clip 44\n",
      "Getting response for clip 45\n",
      "Getting response for clip 46\n",
      "Getting response for clip 47\n",
      "Getting response for clip 48\n",
      "Getting response for clip 49\n",
      "Getting response for clip 50\n",
      "Clip 51 longer than 1 minute, split into segments\n",
      "Getting response for clip 52\n",
      "Getting response for clip 53\n",
      "Getting response for clip 54\n",
      "Getting response for clip 55\n",
      "Getting response for clip 56\n",
      "Getting response for clip 57\n",
      "Getting response for clip 58\n",
      "Getting response for clip 59\n",
      "Getting response for clip 60\n",
      "Getting response for clip 61\n",
      "Getting response for clip 62\n",
      "Getting response for clip 63\n",
      "Getting response for clip 64\n",
      "Getting response for clip 65\n",
      "Getting response for clip 66\n",
      "Getting response for clip 67\n",
      "Getting response for clip 68\n",
      "Getting response for clip 69\n",
      "Getting response for clip 70\n",
      "Getting response for clip 71\n",
      "Getting response for clip 72\n",
      "Getting response for clip 73\n",
      "Getting response for clip 74\n",
      "Getting response for clip 75\n",
      "Getting response for clip 76\n",
      "Getting response for clip 77\n",
      "Getting response for clip 78\n",
      "Getting response for clip 79\n",
      "Getting response for clip 80\n",
      "Getting response for clip 81\n",
      "Getting response for clip 82\n",
      "Getting response for clip 83\n",
      "Getting response for clip 84\n",
      "Getting response for clip 85\n",
      "Getting response for clip 86\n",
      "Getting response for clip 87\n",
      "Getting response for clip 88\n",
      "Getting response for clip 89\n",
      "Getting response for clip 90\n",
      "Getting response for clip 91\n",
      "Getting response for clip 92\n",
      "Getting response for clip 93\n",
      "Getting response for clip 94\n",
      "Getting response for clip 95\n",
      "Getting response for clip 96\n",
      "Getting response for clip 97\n",
      "Getting response for clip 98\n",
      "Getting response for clip 99\n",
      "Getting response for clip 100\n",
      "Getting response for clip 101\n",
      "Getting response for clip 102\n",
      "Getting response for clip 103\n",
      "Getting response for clip 104\n",
      "Getting response for clip 105\n",
      "Getting response for clip 106\n",
      "Getting response for clip 107\n",
      "Getting response for clip 108\n",
      "Getting response for clip 109\n",
      "Getting response for clip 110\n",
      "Getting response for clip 111\n",
      "Getting response for clip 112\n",
      "Getting response for clip 113\n",
      "Getting response for clip 114\n",
      "Getting response for clip 115\n",
      "Getting response for clip 116\n",
      "Getting response for clip 117\n",
      "Getting response for clip 118\n",
      "Getting response for clip 119\n",
      "Getting response for clip 120\n",
      "Getting response for clip 121\n",
      "Getting response for clip 122\n",
      "Getting response for clip 123\n",
      "Getting response for clip 124\n",
      "Getting response for clip 125\n",
      "Getting response for clip 126\n",
      "Getting response for clip 127\n",
      "Getting response for clip 128\n",
      "Getting response for clip 129\n",
      "Getting response for clip 130\n",
      "Getting response for clip 131\n",
      "Getting response for clip 132\n",
      "Getting response for clip 133\n",
      "Getting response for clip 134\n",
      "Getting response for clip 135\n",
      "Getting response for clip 136\n",
      "Getting response for clip 137\n",
      "Getting response for clip 138\n",
      "Getting response for clip 139\n",
      "Getting response for clip 140\n",
      "Getting response for clip 141\n",
      "Getting response for clip 142\n",
      "Getting response for clip 143\n",
      "Getting response for clip 144\n",
      "Getting response for clip 145\n",
      "Getting response for clip 146\n",
      "Getting response for clip 147\n",
      "Getting response for clip 148\n",
      "Getting response for clip 149\n",
      "Getting response for clip 150\n",
      "Getting response for clip 151\n",
      "Getting response for clip 152\n",
      "Getting response for clip 153\n",
      "Getting response for clip 154\n",
      "Getting response for clip 155\n",
      "Getting response for clip 156\n",
      "Getting response for clip 157\n",
      "Getting response for clip 158\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "\n",
    "for clip_num, clip in enumerate(clips):\n",
    "    if len(clip) > 960000:\n",
    "        print(f'Clip {clip_num} longer than 1 minute, split into segments')\n",
    "        n = math.ceil(len(clip) / 960000)\n",
    "        segments = np.array_split(clip, n)\n",
    "        response_segments = []\n",
    "        for segment in segments:\n",
    "            response_segment = gcs(segment, fs)\n",
    "            response_segments.append(response_segment)\n",
    "        response = response_segments[0]\n",
    "        for i in range(1, len(response_segments)):\n",
    "            response.MergeFrom(response_segments[i])\n",
    "    else:\n",
    "        print(f'Getting response for clip {clip_num}')\n",
    "        response = gcs(clip, fs)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "for response in responses:\n",
    "    transcript = ''\n",
    "    for result in response.results:\n",
    "        for alternative in result.alternatives:\n",
    "            transcript = transcript + ' ' + alternative.transcript\n",
    "    transcripts.append(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = [re.sub(' +', ' ', transcript) for transcript in transcripts]\n",
    "transcripts = [transcript.strip() for transcript in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_transcripts = [utterance.lower() for utterance in utterances][:-1] # Omit last utterance\n",
    "google_transcripts = [transcript.lower() for transcript in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_tokens = [transcript.split() for transcript in human_transcripts]\n",
    "google_tokens = [transcript.split() for transcript in google_transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WERs and normalize based on word count\n",
    "total_wc = 0\n",
    "overall_wer = 0\n",
    "\n",
    "for h, g in zip(human_tokens, google_tokens):\n",
    "    total_wc += len(h)\n",
    "    overall_wer += wer(h, g) * len(h)\n",
    "    \n",
    "overall_wer /= total_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4813953488372093"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_wer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiilt",
   "language": "python",
   "name": "tiilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
